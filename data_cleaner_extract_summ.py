# -*- coding: utf-8 -*-
"""Data cleaner extract summ.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cddrjmj_kR-maQ5EoKqix7bTyMRQV2h_
"""

def lcs(X,Y,m,n,Corp_Participants):
  #X,Y=removing_corp(X,Y,Corp_Participants)
  x="BERT-Presentation"
  y="KL-Presentation"
  if x in (X or Y):
    X=X.replace(x,"")
    Y=Y.replace(x,"")
  if y in (Y or X):
    Y=Y.replace(y,"")
    X=X.replace(x,"")
  if X[0]==" ":
    X=X[1:]
  if Y[0]==" ":
    Y=Y[1:]

  X=data_clean(X)
  Y=data_clean(Y)
  X=X.split(".")
  Y=Y.split(".")
  common_text=""
  for i in X:
    if (i in Y and len(word_tokenize(i))>3):
      common_text+=i+"."
  
  return common_text

def finding_complement(X,Y,Corp_Participants):
  #returns Y-X
  X,Y=removing_corp(X,Y,Corp_Participants)
  x="BERT-Presentation"
  y="KL-Presentation"
  if x in (X or Y):
    X=X.replace(x,"")
    Y=Y.replace(x,"")
  if y in (Y or X):
    Y=Y.replace(y,"")
    X=X.replace(x,"")
  if (len(X)>0 and len(Y)>0):
    if X[0]==" ":
      X=X[1:]
    if Y[0]==" ":
      Y=Y[1:]  
    X=data_clean(X)
    Y=data_clean(Y)
    X=X.split(".")
    Y=Y.split(".")
    common_text=[]
    for i in X:
      if i in Y:
        common_text.append(i)
    
    for i in common_text:
      if i in Y :
        index_i=Y.index(i)
        Y.pop(index_i)
    
    text=""
    for i in Y:
      text+=i+"."

    return text
  else:
    return data_clean(Y)

def data_clean(train_data):
  train_data=train_data.replace("\n\n"," ")
  train_data=train_data.replace("\n"," ")
  train_data=train_data.replace(", "," ")
  train_data=train_data.replace(" ,"," ")
  train_data=train_data.replace(","," ")
  train_data=train_data.replace("-"," ")
  train_data=train_data.replace("    "," ")
  train_data=train_data.replace("   "," ")
  train_data=train_data.replace("  "," ") 
  train_data=train_data.replace("<Sentence:","")
  train_data=train_data.replace(">","")
  train_data=train_data.replace("(","")
  train_data=train_data.replace(")","")
  train_data=train_data.replace(".,",".")

  return train_data

def data_extractor(files,PyPDF2):
  pagewise_data=[]#2-D data
  All_docs=[]#All_docs[0] is a list of string of first file
  #pagewise_data[0] list of page wise string of first file-Ali Baba
  All_docs_corporate_participants=[]# a list of strings of corporate participants

  All_docs_questions=[]#2-D list
  #All_docs_questions[0] is a list of all questions of first file 
  All_docs_answers=[]
  All_docs_presentations=[]
  for file_count in range(len(files)):

    pdfFileObj = open(files[file_count],'rb') 
    pdfReader = PyPDF2.PdfFileReader(pdfFileObj) 
    pages=pdfReader.numPages
    data=[]
    for i in range(pages): 
      pageObj = pdfReader.getPage(i) 
      data.append(pageObj.extractText())
    pagewise_data.append(data)
    All_data=[]
    data_str=''
    for i in range(len(data)):
      data_str+=data[i]
    
    data_str=data_str.replace("\n","")
    
    All_data=[data_str]
    All_docs.append(All_data)
    questions=[]
    answers=[]
    
    corporate_Participants_str="CORPORATE PARTICIPANTS "
    presentation_str="PRESENTATION "
    QnA_str="QUESTIONS AND ANSWERS"

    index_i=data_str.index(corporate_Participants_str)
    index_j=data_str.index(presentation_str)
    
    All_docs_corporate_participants.append(data_str[index_i:index_j])
    
    index_i=data_str.index(QnA_str)
    All_docs_presentations.append(data_str[index_j:index_i])
    data_str=data_str[index_i:] #Retaining only QnA  



    count_qna=min(data_str.count("Question:"),data_str.count("Answer:"))
    for count in range(count_qna):   
      i=data_str.index("Question:")
      j=data_str.index("Answer:")
      dup_data_str=data_str[i:j]
      questions.append(dup_data_str)   
      data_str=data_str[j:]
      
      i=data_str.index("Answer:")
      if count!= count_qna-1:
        j=data_str.index("Question:")
        dup_data_str=data_str[i:j]
        x="Answer-"+str(count+1)+" :"
        dup_data_str=dup_data_str.replace("Answer:",x)
      else:
        dup_data_str=data_str[i:]
        x="Answer-"+str(count+1)+" :"
        dup_data_str=dup_data_str.replace("Answer:",x)
      
      answers.append(dup_data_str)#appending answers
      data_str=data_str[j:]
    
    
    All_docs_questions.append(questions)
    All_docs_answers.append(answers) 
  
  return [All_docs_corporate_participants,All_docs_presentations,All_docs_questions,All_docs_answers]

def preparing_presentation_data(doc,corp_participant):
  corp_participant= corp_participant.split("  ")
  for i in range(len(corp_participant)):
    if corp_participant[i][-1]==" ":    
      corp_participant[i]=corp_participant[i][0:(len(corp_participant[i])-1)]

  corp_participant=corp_participant[1:]

  participant_index=[]
    
  for i in range(len(corp_participant)):
    if doc.count(corp_participant[i])>0:
      j= doc.index(corp_participant[i])
      participant_index.append(j)
    else:
      participant_index.append(0)

  dup_participant_index=participant_index[:]
  dup_corp_participant=[]
  dup_participant_index.sort()

  for i in dup_participant_index:
    if i!=0:
      index_i= participant_index.index(i)
      dup_corp_participant.append(corp_participant[index_i])

  presentation_doc=[]

  for i in range(len(dup_corp_participant)-1):
    index_i=doc.index(dup_corp_participant[i])
    index_j=doc.index(dup_corp_participant[i+1])
    x=doc[index_i:index_j]
    x=x.replace(dup_corp_participant[i],dup_corp_participant[i]+"\n\n")
    presentation_doc.append(x)
    if i+1==len(dup_corp_participant)-1:
      x=doc[index_j:]
      x=x.replace(dup_corp_participant[i+1],dup_corp_participant[i+1]+"\n\n")
      presentation_doc.append(x)
    


  if len(dup_corp_participant)==1:
    
    index_i=doc.index(dup_corp_participant[0])
    x=doc[index_i:]
    x=x.replace(dup_corp_participant[0],dup_corp_participant[0]+"\n\n")
    presentation_doc.append(x)

    
  return presentation_doc,dup_corp_participant